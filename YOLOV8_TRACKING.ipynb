{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "s_uXEjy_f1Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "O8iQIz7SSOi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 製造測試影片\n",
        "\n",
        "# 原始影片檔案太大，直接跑model.track會讓colab直接讓RAM過載，因此先將影片每五幀截取一張，壓成影片再進行預測\n",
        "# 有另一種方式是修改model.track裡面的vid_stride，預設1是每幀讀，數字越大跳過幀數越多，例如model.track(test.mp4, vid_stride=5)可以達成一樣每五幀截取一張的效果\n",
        "# 不過壓成影片會花的時間和運算元多很多，不如直接截取,但取得的是影片檔但RAM不足時推薦使用"
      ],
      "metadata": {
        "id": "qCx6-aWIHSav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/drive/MyDrive/MOT17/test/MOT17-03-FRCNN/img1/'\n",
        "selected_test_path = []\n",
        "for i in range(100,800,5):# 由100開始是因為圖片檔名為000001，使用1或2位數會造成圖片檔名少了0因此錯誤，如果一定需要可以添加判斷式 if i<10 : print(f'00{i}') elif i<100: print(f'0{i}')來解決\n",
        "  selected_test_path.append(f'{test_path}000{i}.jpg')\n",
        "print(selected_test_path[:3])"
      ],
      "metadata": {
        "id": "wue-n8gxSaqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 獲取測試影片大小\n",
        "sample_img = cv2.imread(selected_test_path[0]) # 取第一張作為樣本就可以知道影片大小\n",
        "height, width, layers = sample_img.shape"
      ],
      "metadata": {
        "id": "N7A2QO0TQfxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 參考資料 官網 https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html\n",
        "\n",
        "output_video_path = \"/content/selected_test.mp4\" # 影片輸出位置\n",
        "   # 寫入格式.mp4使用的是mp4v\n",
        "video_writer = cv2.VideoWriter(output_video_path, fourcc, 6, (width, height)) # 參數分別為(輸出位置，編碼，每秒幀數，圖片大小) 原片30幀，因裁為1/5，因此參數放入6幀\n",
        "# 寫入影片\n",
        "for path in selected_test_path:\n",
        "    img = cv2.imread(path)\n",
        "    video_writer.write(img)\n",
        "# 關閉video_writer\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(f\"影片位置{output_video_path}\")"
      ],
      "metadata": {
        "id": "2ui3wzoVT0vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 資料測試\n",
        "# 程式源自yolov8官網教學 https://docs.ultralytics.com/zh/modes/track/#persisting-tracks-loop\n",
        "# 結合cv2影片存取\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')\n",
        "\n",
        "# 用cap擷取影片\n",
        "video_path = output_video_path\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# 儲存track_history 用於ID標註等\n",
        "track_history = defaultdict(lambda: [])\n",
        "# 影片存取器\n",
        "video_writer_result = cv2.VideoWriter('/content/Tracking_result.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 6, (width, height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    # 讀取影格\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # 跑YOLOv8，參數寫在官網\n",
        "        results = model.track(frame, persist=True, show_labels=False, show_conf=False, save_txt=True)\n",
        "        # reset track_id\n",
        "        track_ids = []\n",
        "\n",
        "        # 取得Box和track IDs\n",
        "        boxes = results[0].boxes.xywh.cpu()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "\n",
        "        # 疊BOX及track IDs至圖片\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # 畫出追蹤\n",
        "\n",
        "        for box, track_id in zip(boxes, track_ids):\n",
        "            x, y, w, h = box\n",
        "            track = track_history[track_id]\n",
        "            track.append((float(x), float(y)))  # x, y center point\n",
        "            if len(track) > 30:  # retain 90 tracks for 90 frames\n",
        "                track.pop(0)\n",
        "\n",
        "            # 劃出軌跡\n",
        "\n",
        "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(151, 255, 255), thickness=8)\n",
        "\n",
        "        # 顯示含有Box、track IDs、軌跡的圖，但在colab跑，需要使用cv2_imshow，不能用原本的cv2.imshow()\n",
        "\n",
        "        video_writer_result.write(annotated_frame)\n",
        "\n",
        "        # 跑cv2_imshow也會吃運算元，我寫入影片了，就不將結果顯示，如果需要就拿掉註解\n",
        "        \t# 在本地運行使用cv2.imshow()需要多加一個瀏覽器名稱\n",
        "\t        # 例如cv2.imshow(‘annotated_frame’, annotated_frame)\n",
        "        # cv2_imshow(annotated_frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "\n",
        "# 最後加入，用於關閉cap和writer\n",
        "cap.release()\n",
        "video_writer_result.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "nB_4V4Q1fKiF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}